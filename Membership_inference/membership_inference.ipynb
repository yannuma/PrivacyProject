{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff1163b-8acf-4daa-a1bd-a845726c5633",
   "metadata": {
    "id": "1ff1163b-8acf-4daa-a1bd-a845726c5633"
   },
   "source": [
    "Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b70347-7b0c-4fa3-a810-58280f7fdbf0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46b70347-7b0c-4fa3-a810-58280f7fdbf0",
    "outputId": "c3720412-1793-4590-975d-eff9510c1379",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install opacus\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.validators import ModuleValidator\n",
    "import tarfile\n",
    "import torch\n",
    "import requests\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.utils.data as torch_data\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "#from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2fa083-baf9-445d-b38f-a8eeff818816",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e2fa083-baf9-445d-b38f-a8eeff818816",
    "outputId": "89be82f0-ba17-42c0-f532-c56f5410f50f"
   },
   "outputs": [],
   "source": [
    "## download the data\n",
    "response = requests.get(f'https://www.comp.nus.edu.sg/~reza/files/dataset_texas.tgz')\n",
    "if response.status_code == 200:\n",
    "    with open(f'dataset_texas.tgz', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Download completed successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to download file: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e3cb2d-795c-4b0b-b09a-eeb1f2a010af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tarfile.open(f'dataset_texas.tgz') as f:\n",
    "    f.extractall(f'data/')\n",
    "\n",
    "with open('data/texas/100/feats', 'r') as f:\n",
    "    features = f.readlines()\n",
    "with open('data/texas/100/labels', 'r') as f:\n",
    "    labels = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "BHmHyjxQ507w",
   "metadata": {
    "id": "BHmHyjxQ507w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## build the sampled trainig and test datasets\n",
    "features_list = [list(map(int, ''.join(feature.split()).split(','))) for feature in features]\n",
    "labels_list = [int(label.strip()) for label in labels]\n",
    "size = int(0.8 * len(features))\n",
    "sample_size = 100\n",
    "## sample dataset for inference attacks\n",
    "feat_tens = torch.tensor(features_list[size-sample_size:size+sample_size], dtype=torch.float)\n",
    "l_tens = torch.tensor(labels_list[size-sample_size:size+sample_size], dtype=torch.long)\n",
    "dataset = TensorDataset(feat_tens, l_tens)\n",
    "\n",
    "\n",
    "## true train and test datasets\n",
    "feat_tens_train = torch.tensor(features_list[size-sample_size:size], dtype=torch.float)\n",
    "l_tens_train = torch.tensor(labels_list[size-sample_size:size], dtype=torch.long)\n",
    "#feat_tens_test = torch.tensor(features_list[size:], dtype=torch.float)\n",
    "#l_tens_test = torch.tensor(labels_list[size:], dtype=torch.long)\n",
    "dataset_train = TensorDataset(feat_tens_train, l_tens_train)\n",
    "#dataset_test = TensorDataset(feat_tens_test, l_tens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "znqd_4ZPE6YN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "znqd_4ZPE6YN",
    "outputId": "4f0fe336-293f-435e-d2bb-d1527190b8c8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ale_m\\Desktop\\Alles\\Università\\Unibas\\03 Privacy-preserving methods\\PrivacyProject\\Membership_inference\n",
      "C:\\Users\\ale_m\\Desktop\\Alles\\Università\\Unibas\\03 Privacy-preserving methods\\PrivacyProject\\Membership_inference\\..\\Models\\model_S.pth\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "current_dir = os.getcwd()\n",
    "model_path = os.path.join(current_dir,'..','Models','model_S.pth')\n",
    "\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b6eb6d1-7240-4bde-9028-7420ddb164fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## model class\n",
    "class NetSeq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetSeq, self).__init__()\n",
    "        self.fc1 = nn.Linear(6169, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 101)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "xrxwfbsqCWkH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "xrxwfbsqCWkH",
    "outputId": "7d805a44-afa9-4c8d-a98e-4bfe2a83a935",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetSeq(\n",
       "  (fc1): Linear(in_features=6169, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=101, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load the model\n",
    "model_state_dict = torch.load(model_path)\n",
    "model = NetSeq()\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63aa3044-50f8-4f8a-9277-d6ab5dad8494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "100\n",
      "8 0.2831069827079773\n"
     ]
    }
   ],
   "source": [
    "## evaluate the model and compute loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "data_loader = DataLoader(dataset, batch_size = 1, shuffle = False)\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for feat, lab in data_loader:\n",
    "            # Forward pass\n",
    "        outputs = model(feat)    \n",
    "            # Compute loss\n",
    "        loss = criterion(outputs, lab)\n",
    "            \n",
    "            # Store the feature values and loss\n",
    "        results.append((feat.numpy(), lab.numpy(), loss.item()))\n",
    "\n",
    "## sort per loss increasingly\n",
    "sorted_results = sorted(results, key = lambda x: x[2])\n",
    "predicted_members = sorted_results[:sample_size]\n",
    "print(len(sorted_results))\n",
    "print(len(predicted_members))\n",
    "##print(sorted_results[999][2])\n",
    "## max loss as an upper bound for threshold in a ROC curve\n",
    "max_loss = sorted_results[len(sorted_results)-1][2]\n",
    "max_loss2 = predicted_members[len(predicted_members)-1][2]\n",
    "int_max_loss = math.ceil(max_loss)\n",
    "print(int_max_loss, max_loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "932b2cf2-3a28-422a-8b07-930e05fb47cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolute number of correct predictions: 53\n",
      "accuracy of prediction: 0.53\n"
     ]
    }
   ],
   "source": [
    "## the idea is that the value for which the loss is smaller are the one that are more likely to be member of the training set\n",
    "trainloader = DataLoader(dataset_train, batch_size=1, shuffle=False)\n",
    "\n",
    "train_features_set = {tuple(features.numpy().flatten()) for features, _ in trainloader}\n",
    "\n",
    "count_actual_members = sum(1 for feats, lab, loss in predicted_members if tuple(feats.flatten()) in train_features_set)\n",
    "\n",
    "        \n",
    "print('absolute number of correct predictions:',count_actual_members)\n",
    "print('accuracy of prediction:', count_actual_members/sample_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4d0aac-e691-4fdf-8698-e1b5bb938c17",
   "metadata": {
    "id": "af4d0aac-e691-4fdf-8698-e1b5bb938c17"
   },
   "outputs": [],
   "source": [
    "model = 'blabla' ## salvati come pth\n",
    "\n",
    "\n",
    "x, y = 'sample of n elements'  ## check how to sample from tensor datasets\n",
    "losses = 'array of losses for model(x), y'\n",
    "sorted_elem = 'sort losses increasingly'\n",
    "\n",
    "## assume that 50% of x are in the training set\n",
    "## pick first n/2 x wrt to sorted loss\n",
    "## check how many of these are actually in the training dataset\n",
    "\n",
    "## in case of unknown percentage\n",
    "max_loss = 'max loss'\n",
    "threshold = 'between 0 and max_loss, intervall max_loss/100'\n",
    "\n",
    "## ROc curve, for each threshold comupte how many x are chosen as members\n",
    "## compute ratio TPR/FPR and plot the curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f3d6ca-bf1b-47e4-b696-001c35490783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
